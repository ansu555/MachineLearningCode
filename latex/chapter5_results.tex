\section{Results and Analysis}

\subsection{Experimental Setup}

Experiments were conducted using Apple Inc. (AAPL) historical stock data from 2010 to 2025 (approximately 3,773 trading days). The dataset was split chronologically: 80\% training, 20\% testing. Models were evaluated using RMSE, $R^2$ score, MAE, and directional accuracy.

\subsection{Exploratory Data Analysis}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{images/results/Stock_Price_Prediction_Data_Visualization_img_0.png}
    \caption{Historical Closing Price of AAPL (2010-2025)}
    \label{fig:eda_close}
\end{figure}

Figure \ref{fig:eda_close} reveals strong non-stationarity with accelerating upward trend, increasing volatility in recent years, and clear volatility clustering. The data exhibits high autocorrelation, right-skewed price distribution, and significant seasonal patterns—characteristics that informed our hybrid modeling strategy.

\subsection{Model Performance Evaluation}

We evaluated eight models across four categories: statistical methods, traditional machine learning, deep learning, and hybrid approaches.

\subsubsection{Statistical Models}

\textbf{ARIMA} failed catastrophically (RMSE: 32.52, $R^2$: -0.0868) due to inadequate handling of strong trends and linear assumptions violations. \textbf{SARIMA} showed dramatic improvement (RMSE: 3.24, $R^2$: 0.9891), demonstrating the importance of seasonal awareness for financial time series.

\subsubsection{Machine Learning Models}

\textbf{Linear Regression} achieved surprisingly strong performance (RMSE: 2.92, $R^2$: 0.9913) through effective feature engineering with lag features and technical indicators. However, tree-based models failed dramatically: \textbf{Random Forest} (RMSE: 27.79) and \textbf{XGBoost} (RMSE: 27.13) both suffered from fundamental extrapolation limitations—unable to predict beyond training data ranges as prices trended upward.

\subsubsection{Deep Learning Models}

\textbf{Univariate LSTM} (RMSE: 4.52, $R^2$: 0.9792) and \textbf{BiLSTM + Attention} (RMSE: 4.28, $R^2$: 0.9722) demonstrated strong temporal pattern learning. The BiLSTM architecture processed sequences bidirectionally with a custom attention mechanism, achieving marginal improvement (5.3\%) over univariate LSTM at 3.4x parameter cost—demonstrating diminishing returns from added complexity.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{images/results/Stock_Price_Prediction_Forecasting(Next_Day's_Price)_img_7.png}
    \caption{BiLSTM + Attention Training History}
    \label{fig:bilstm_training}
\end{figure}

\subsection{Hybrid Model: SARIMA + XGBoost}

\subsubsection{Methodology}

The hybrid model decomposes financial time series as: $y_t = L_t + N_t + \epsilon_t$, where $L_t$ represents linear components (trend, seasonality) and $N_t$ represents non-linear patterns. Our three-stage approach:

\begin{enumerate}
    \item \textbf{SARIMA baseline}: Captures trend and seasonal patterns ($L_t$)
    \item \textbf{XGBoost residual modeling}: Learns non-linear deviations ($N_t$) from SARIMA predictions using engineered features
    \item \textbf{Hybrid fusion}: $\hat{y}_t^{Hybrid} = \hat{y}_t^{SARIMA} + \hat{r}_t^{XGBoost}$
\end{enumerate}

This formulation eliminates XGBoost's extrapolation problem by operating on approximately stationary residuals rather than trending prices.

\subsubsection{Performance Results}

The hybrid model achieved exceptional performance:
\begin{itemize}
    \item \textbf{RMSE:} 1.28 (best among all models)
    \item \textbf{$R^2$ Score:} 0.9983 (99.83\% variance explained)
    \item \textbf{MAE:} 0.95
    \item \textbf{Directional Accuracy:} 87\%
\end{itemize}

This represents 56.2\% improvement over Linear Regression, 71.7\% over BiLSTM+Attention, and 95.3\% over standalone XGBoost.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.85\textwidth]{images/results/Stock_Price_Prediction_Forecasting(Next_Day's_Price)_img_9.png}
    \caption{Hybrid Model (SARIMA + XGBoost) Predictions vs Actual Prices}
    \label{fig:hybrid_results}
\end{figure}

Figure \ref{fig:hybrid_results} demonstrates the hybrid model's exceptional fit, closely tracking actual prices across the entire test period with minimal lag.

\subsection{Comprehensive Comparison}

\begin{table}[htbp]
\centering
\caption{Performance Comparison of All Models}
\label{tab:model_comparison_compact}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Model} & \textbf{RMSE} & \textbf{$R^2$} & \textbf{Dir. Acc.} & \textbf{Train Time} \\ \midrule
ARIMA & 32.52 & -0.0868 & ~52\% & 1-2 min \\
SARIMA & 3.24 & 0.9891 & ~78\% & 2-3 min \\
Linear Regression & 2.92 & 0.9913 & ~80\% & \textless 1 min \\
Random Forest & 27.79 & 0.2064 & ~55\% & 3-4 min \\
XGBoost & 27.13 & 0.2435 & ~57\% & 3-5 min \\
Univariate LSTM & 4.52 & 0.9792 & ~75\% & 10-15 min \\
BiLSTM + Attention & 4.28 & 0.9722 & ~77\% & 15-20 min \\
\textbf{Hybrid (SARIMA+XGB)} & \textbf{1.28} & \textbf{0.9983} & \textbf{~87\%} & \textbf{~5 min} \\ \bottomrule
\end{tabular}
\end{table}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{images/results/Stock_Price_Prediction_Forecasting(Next_Day's_Price)_img_10.png}
    \caption{Comparison of All Model Predictions}
    \label{fig:model_comparison_all}
\end{figure}

Figure \ref{fig:model_comparison_all} visually confirms the hybrid model's superiority, tracking actual prices most closely while tree models exhibit systematic underprediction and ARIMA completely fails.

\subsection{Discussion}

\subsubsection{Key Findings}

\textbf{1. Problem Formulation Matters}: The same XGBoost algorithm that failed standalone (RMSE: 27.13) became the best performer when applied to detrended residuals (hybrid RMSE: 1.28)—a 95.3\% improvement solely from reformulation.

\textbf{2. Hybrid Superiority}: Combining statistical rigor (SARIMA) with machine learning flexibility (XGBoost) achieved 99.83\% variance explained, outperforming deep learning despite lower complexity.

\textbf{3. Feature Engineering Impact}: Linear regression's competitive performance (RMSE: 2.92) validates that thoughtful feature engineering enables simple models to rival complex architectures.

\textbf{4. Seasonal Awareness Critical}: SARIMA's 10-fold improvement over ARIMA (RMSE: 3.24 vs 32.52) demonstrates the necessity of modeling calendar effects.

\textbf{5. Diminishing Returns from Complexity}: BiLSTM + Attention's marginal 5.3\% improvement over simpler LSTM at 3.4x parameter cost suggests complexity doesn't guarantee superior performance.

\subsubsection{Practical Implications}

For AAPL trading at ~\$180-220, the hybrid model's RMSE of \$1.28 represents ~0.6\% error with 87\% directional accuracy—potentially viable for trading applications pending consideration of transaction costs, slippage, and risk management.

Training efficiency (5 minutes) and computational simplicity (CPU-only) make the hybrid approach more practical for deployment than computationally intensive deep learning alternatives (15-20 minutes, benefit from GPU).

\subsubsection{Limitations}

\textbf{Data}: Single stock (AAPL only), bull market bias (2010-2025), no crisis period testing, survivorship bias assumptions.

\textbf{Model}: Point predictions without uncertainty quantification, no regime change detection, limited to next-day horizon, assumes stationary feature-target relationships.

\textbf{Implementation}: Hyperparameter sensitivity, unclear optimal retraining frequency, interpretability challenges for deep learning components.

\subsubsection{Literature Alignment}

Our results validate Chapter 2's literature review predictions: hybrid models outperform single-method approaches (confirmed with 56\% improvement), temporal modeling proves critical (LSTM vs trees: 96\% higher $R^2$), and 1D processing of raw signals superior to image-based approaches.

\subsubsection{Future Directions}

\textbf{Uncertainty Quantification}: Bayesian networks, quantile regression, or ensemble methods for prediction intervals and risk metrics.

\textbf{Adaptive Learning}: Online learning for concept drift, regime detection, meta-learning for rapid adaptation to changing market dynamics.

\textbf{Multimodal Enhancement}: Incorporate NLP sentiment from news/social media, alternative data sources, cross-asset relationships.

\textbf{Broader Validation}: Test across multiple stocks, sectors, international markets, and crucially—crisis periods missing from current dataset.

\subsection{Conclusion}

This comprehensive evaluation demonstrates that hybrid SARIMA+XGBoost architecture achieves state-of-the-art next-day stock prediction, outperforming eight alternatives including sophisticated deep learning models. Key insights: (1) hybridization yields dramatic improvements, (2) problem formulation matters as much as algorithm selection, (3) feature engineering remains critical even in the deep learning era, (4) seasonal awareness essential for financial data, (5) complexity shows diminishing returns.

The exceptional performance (RMSE: 1.28, 99.83\% $R^2$, 87\% directional accuracy) demonstrates practical viability, though significant work remains in uncertainty quantification, regime adaptation, and validation across diverse market conditions before production deployment.
